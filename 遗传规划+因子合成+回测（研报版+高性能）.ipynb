{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-ai904/Huatai-Model/blob/main/%E9%81%97%E4%BC%A0%E8%A7%84%E5%88%92%2B%E5%9B%A0%E5%AD%90%E5%90%88%E6%88%90%2B%E5%9B%9E%E6%B5%8B%EF%BC%88%E7%A0%94%E6%8A%A5%E7%89%88%2B%E9%AB%98%E6%80%A7%E8%83%BD%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tushare bottleneck\n",
        "import tushare as ts\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import bottleneck as bn\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-12T08:57:22.605947Z",
          "iopub.status.idle": "2025-04-12T08:57:24.081026Z",
          "shell.execute_reply.started": "2025-04-12T08:57:22.606357Z",
          "shell.execute_reply": "2025-04-12T08:57:24.079938Z"
        },
        "id": "wsS1vVYXOJfE"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置Tushare API Token并初始化\n",
        "ts.set_token('2876ea85cb005fb5fa17c809a98174f2d5aae8b1f830110a5ead6211')\n",
        "pro = ts.pro_api()\n"
      ],
      "metadata": {
        "id": "T75P3LmWVr5V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取沪深300成分股前50\n",
        "def get_hs300_top50(start_date , end_date):\n",
        "    try:\n",
        "        df = pro.index_weight(index_code='000001.SH', start_date= start_date, end_date= end_date)\n",
        "        if df.empty:\n",
        "            raise ValueError(\"未获取到沪深300成分股数据\")\n",
        "\n",
        "        df = df.sort_values('weight', ascending=False)\n",
        "        stock_list = df['con_code'].unique()[:100].tolist()\n",
        "        print(f\"成功获取沪深300前50只股票: {stock_list[:6]}...（共 {len(stock_list)} 只）\")\n",
        "        return stock_list\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"获取沪深300成分股失败: {e}\")\n",
        "        return []\n",
        "\n",
        "# 获取股票日频数据\n",
        "def get_data(start_date, end_date, stock_list):\n",
        "    df_list = []\n",
        "    for stock in stock_list:\n",
        "        try:\n",
        "            temp_df = pro.daily(\n",
        "                ts_code=stock,\n",
        "                start_date=start_date,\n",
        "                end_date=end_date,\n",
        "                fields='ts_code,trade_date,open,close,high,low,vol,pct_chg'\n",
        "            )\n",
        "            if not temp_df.empty:\n",
        "                # print(f\"股票 {stock} 在 {start_date} 至 {end_date} 获取到 {len(temp_df)} 条数据\")\n",
        "                df_list.append(temp_df)\n",
        "            else:\n",
        "                print(f\"股票 {stock} 在 {start_date} 至 {end_date} 无数据\")\n",
        "        except Exception as e:\n",
        "            print(f\"获取股票 {stock} 数据失败: {e}\")\n",
        "\n",
        "    if not df_list:\n",
        "        print(f\"时间范围 {start_date} 至 {end_date} 无任何股票数据\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = pd.concat(df_list)\n",
        "        df.rename(columns={'vol': 'volume', 'pct_chg': 'return'}, inplace=True)\n",
        "        df['return'] = df['return'] / 100\n",
        "        df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
        "\n",
        "        # 检查并移除重复的 trade_date 和 ts_code 组合\n",
        "        duplicates = df.duplicated(subset=['trade_date', 'ts_code'], keep=False)\n",
        "        if duplicates.any():\n",
        "            print(f\"警告: 发现重复数据，共 {duplicates.sum()} 条，自动保留最后一条\")\n",
        "            df = df.drop_duplicates(subset=['trade_date', 'ts_code'], keep='last')\n",
        "\n",
        "        # 重塑数据\n",
        "        df_pivot = df.pivot(index='trade_date', columns='ts_code')\n",
        "\n",
        "        # 检查收益率数据\n",
        "        if 'return' in df_pivot:\n",
        "            return_stats = df_pivot['return'].describe()\n",
        "            print(f\"收益率统计: {return_stats}\")\n",
        "            # 过滤收益率全为 NaN 或常数的股票\n",
        "            valid_stocks = return_stats.loc['std'] > 0\n",
        "            valid_stocks = valid_stocks[valid_stocks].index.tolist()\n",
        "            if not valid_stocks:\n",
        "                print(\"所有股票的收益率均为常数或 NaN，无法继续\")\n",
        "                return pd.DataFrame()\n",
        "            df_pivot = df_pivot.loc[:, df_pivot.columns.get_level_values(1).isin(valid_stocks)]\n",
        "\n",
        "        return df_pivot\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"数据合并失败: {e}\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-12T08:57:24.082705Z",
          "iopub.execute_input": "2025-04-12T08:57:24.083075Z",
          "iopub.status.idle": "2025-04-12T08:57:24.090339Z",
          "shell.execute_reply.started": "2025-04-12T08:57:24.083039Z",
          "shell.execute_reply": "2025-04-12T08:57:24.089233Z"
        },
        "id": "-8aTVgNAOJfF"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "# 中位数去极值函数\n",
        "def winsorize_median(factor, n_mad=5):\n",
        "    factor = factor.copy()\n",
        "    # 计算中位数\n",
        "    median = np.nanmedian(factor)\n",
        "    # 计算中位数绝对偏差 (MAD)\n",
        "    mad = np.nanmedian(np.abs(factor - median))\n",
        "    # 设定上下限\n",
        "    upper = median + n_mad * mad\n",
        "    lower = median - n_mad * mad\n",
        "    # 截断极值\n",
        "    factor = np.clip(factor, lower, upper)\n",
        "    return factor"
      ],
      "metadata": {
        "id": "x6MDq_8nNY43"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 标准化函数\n",
        "def standardize(factor):\n",
        "    factor = factor.copy()\n",
        "    mean = np.nanmean(factor)\n",
        "    std = np.nanstd(factor)\n",
        "    return (factor - mean) / (std + 1e-10)  # 避免除以零"
      ],
      "metadata": {
        "id": "wbC2ku3mNc_H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算所有因子的值\n",
        "def calculate_all_factors(data, factor_expressions, target_shape):\n",
        "    factors = []\n",
        "    # 使用 target 的展平长度来确定样本数\n",
        "    expected_length = target_shape[0]\n",
        "    for expr in factor_expressions:\n",
        "        try:\n",
        "            # 计算因子值\n",
        "            factor_values = eval(expr, {'np': np, 'bn': bn}, {'data': data})\n",
        "            # 展平为1维数组\n",
        "            if isinstance(factor_values, pd.DataFrame):\n",
        "                factor_values_flat = factor_values.values.flatten()\n",
        "            else:\n",
        "                factor_values_flat = factor_values.flatten()\n",
        "            # 确保因子值长度与 target 对齐\n",
        "            if len(factor_values_flat) != expected_length:\n",
        "                print(f\"因子 {expr} 的展平长度 {len(factor_values_flat)} 与目标长度 {expected_length} 不一致，调整中...\")\n",
        "                # 截断或填充因子值\n",
        "                if len(factor_values_flat) > expected_length:\n",
        "                    factor_values_flat = factor_values_flat[:expected_length]\n",
        "                else:\n",
        "                    # 填充 NaN 至目标长度\n",
        "                    factor_values_flat = np.pad(factor_values_flat, (0, expected_length - len(factor_values_flat)),\n",
        "                                               mode='constant', constant_values=np.nan)\n",
        "            # 去极值和标准化\n",
        "            factor_values_flat = standardize(winsorize_median(factor_values_flat))\n",
        "            factors.append(factor_values_flat)\n",
        "        except Exception as e:\n",
        "            print(f\"计算因子 {expr} 失败: {e}\")\n",
        "            factors.append(np.full(expected_length, np.nan))\n",
        "\n",
        "    # 转换为 (样本数, 因子数) 的矩阵\n",
        "    factors = np.array(factors).T\n",
        "    return factors"
      ],
      "metadata": {
        "id": "LwuixP4fNetP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用随机森林进行因子合成\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 使用随机森林进行因子合成\n",
        "def synthesize_with_random_forest(factors, target, test_size=0.2, random_state=42):\n",
        "    # 确保 factors 和 target 的样本数一致\n",
        "    if factors.shape[0] != len(target):\n",
        "        raise ValueError(f\"factors 形状 {factors.shape[0]} 与 target 长度 {len(target)} 不一致\")\n",
        "\n",
        "    # 确保没有 NaN 值\n",
        "    valid_mask = ~np.any(np.isnan(factors), axis=1) & ~np.isnan(target)\n",
        "    factors_clean = factors[valid_mask]\n",
        "    target_clean = target[valid_mask]\n",
        "\n",
        "    if len(factors_clean) < 2:\n",
        "        print(\"有效数据点少于2，无法进行随机森林训练\")\n",
        "        return np.full(len(target), np.nan), None\n",
        "\n",
        "    # 划分训练集和测试集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        factors_clean, target_clean, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 训练随机森林模型\n",
        "    rf = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # 预测\n",
        "    y_pred_train = rf.predict(X_train)\n",
        "    y_pred_test = rf.predict(X_test)\n",
        "\n",
        "    # 计算 MSE\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "    print(f\"Train MSE: {mse_train:.6f}, Test MSE: {mse_test:.6f}\")\n",
        "\n",
        "    # 预测整个数据集\n",
        "    final_factor = np.full(len(target), np.nan)\n",
        "    final_factor[valid_mask] = rf.predict(factors[valid_mask])\n",
        "\n",
        "    # 标准化最终因子\n",
        "    final_factor = standardize(final_factor)\n",
        "\n",
        "    return final_factor, rf"
      ],
      "metadata": {
        "id": "t_GgO2ngNgZn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存结果\n",
        "def save_results(final_factor, data, output_path=\"synthetic_factor.csv\"):\n",
        "    # 确保 final_factor 的长度与 data.index 对齐\n",
        "    if len(final_factor) != len(data.index):\n",
        "        print(f\"final_factor 长度 {len(final_factor)} 与 data.index 长度 {len(data.index)} 不一致，调整中...\")\n",
        "        min_length = min(len(final_factor), len(data.index))\n",
        "        final_factor = final_factor[:min_length]\n",
        "        data_subset = data.iloc[:min_length]\n",
        "    else:\n",
        "        data_subset = data\n",
        "\n",
        "    result_df = pd.DataFrame({\n",
        "        'date': data_subset.index,\n",
        "        'synthetic_factor': final_factor\n",
        "    })\n",
        "    result_df.to_csv(output_path, index=False)\n",
        "    print(f\"合成因子已保存至 {output_path}\")\n"
      ],
      "metadata": {
        "id": "ffOkmN6-NikG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化种群\n",
        "def initialize_population(size, function_list):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        formula = random.choice(function_list)\n",
        "        population.append(formula)\n",
        "    return population\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-12T08:57:24.091587Z",
          "iopub.execute_input": "2025-04-12T08:57:24.091942Z",
          "iopub.status.idle": "2025-04-12T08:57:24.113795Z",
          "shell.execute_reply.started": "2025-04-12T08:57:24.091909Z",
          "shell.execute_reply": "2025-04-12T08:57:24.112742Z"
        },
        "id": "cgIhvkdcOJfF"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "# 修改后的 calculate_fitness 函数\n",
        "def calculate_fitness(formula, data):\n",
        "    try:\n",
        "        factor_values = eval(formula, {'np': np, 'bn': bn}, {'data': data})\n",
        "        # 将 factor_values 转换为 numpy 数组并展平\n",
        "        if isinstance(factor_values, pd.DataFrame):\n",
        "            factor_values_flat = factor_values.values.flatten()\n",
        "        else:\n",
        "            factor_values_flat = factor_values.flatten()\n",
        "        # 将 returns 转换为 numpy 数组并展平\n",
        "        returns_flat = data['return'].values.flatten()\n",
        "\n",
        "        # 检查数据\n",
        "        # print(f\"因子公式: {formula}\")\n",
        "        # print(f\"因子值形状: {factor_values.shape if isinstance(factor_values, (pd.DataFrame, np.ndarray)) else 'N/A'}, 展平后: {factor_values_flat.shape}\")\n",
        "        print(f\"因子值统计: min={np.nanmin(factor_values_flat):.4f}, max={np.nanmax(factor_values_flat):.4f}, std={np.nanstd(factor_values_flat):.4f}\")\n",
        "        # print(f\"因子值 NaN 比例: {np.isnan(factor_values_flat).mean():.4f}\")\n",
        "        print(f\"收益率形状: {data['return'].shape}, 展平后: {returns_flat.shape}\")\n",
        "        print(f\"收益率统计: min={np.nanmin(returns_flat):.4f}, max={np.nanmax(returns_flat):.4f}, std={np.nanstd(returns_flat):.4f}\")\n",
        "        # print(f\"收益率 NaN 比例: {np.isnan(returns_flat).mean():.4f}\")\n",
        "\n",
        "        mask = ~(np.isnan(factor_values_flat) | np.isnan(returns_flat))\n",
        "        if mask.sum() < 2:\n",
        "            print(\"有效数据点少于 2，无法计算相关性\")\n",
        "            return -1\n",
        "\n",
        "        # 检查是否为常数\n",
        "        if np.nanstd(factor_values_flat[mask]) == 0 or np.nanstd(returns_flat[mask]) == 0:\n",
        "            print(\"因子值或收益率是常数，无法计算相关性\")\n",
        "            return -1\n",
        "\n",
        "        corr, _ = spearmanr(factor_values_flat[mask], returns_flat[mask])\n",
        "        print(f\"RankIC(corr): {corr:.4f}\")\n",
        "        return corr if not np.isnan(corr) else -1\n",
        "    except Exception as e:\n",
        "        print(f\"计算适应度失败: {e}\")\n",
        "        return -1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-12T08:57:24.115528Z",
          "iopub.execute_input": "2025-04-12T08:57:24.116034Z",
          "iopub.status.idle": "2025-04-12T08:57:24.13586Z",
          "shell.execute_reply.started": "2025-04-12T08:57:24.116006Z",
          "shell.execute_reply": "2025-04-12T08:57:24.13486Z"
        },
        "id": "d2j40C2lOJfF"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "def evolve_population(population, data, generations):\n",
        "    for gen in range(generations):\n",
        "        fitness_scores = [(formula, calculate_fitness(formula, data)) for formula in population]\n",
        "        # 打印 fitness_scores 的统计信息\n",
        "        scores = [score for _, score in fitness_scores if not np.isnan(score)]\n",
        "        print(f\"第 {gen+1} 代，适应度统计: min={min(scores) if scores else 'N/A'}, max={max(scores) if scores else 'N/A'}, mean={np.mean(scores) if scores else 'N/A'}\")\n",
        "\n",
        "        fitness_scores = sorted(fitness_scores, key=lambda x: x[1], reverse=True)[:int(len(fitness_scores)*0.6)]\n",
        "        # 暂时移除筛选条件，确保种群不为空\n",
        "        population = [item[0] for item in fitness_scores if item[1] > 0.015]\n",
        "\n",
        "        print(f\"第 {gen+1} 代，筛选后种群大小: {len(population)}\")\n",
        "\n",
        "        if not population:\n",
        "            print(\"种群为空，停止进化，可能是因子公式无效或数据问题\")\n",
        "            return []\n",
        "\n",
        "        new_population = []\n",
        "        while len(new_population) < len(population):\n",
        "            parent1, parent2 = random.sample(population, 2)\n",
        "            new_formula = f\"({parent1}) + ({parent2})\"\n",
        "            if random.random() < 0.1:\n",
        "                operations = ['+', '*', '-']\n",
        "                new_formula = new_formula.replace('+', random.choice(operations))\n",
        "            new_population.append(new_formula)\n",
        "        population = new_population[:len(population)]\n",
        "\n",
        "    return population"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-12T08:57:24.137008Z",
          "iopub.execute_input": "2025-04-12T08:57:24.137298Z",
          "iopub.status.idle": "2025-04-12T08:57:24.155697Z",
          "shell.execute_reply.started": "2025-04-12T08:57:24.137268Z",
          "shell.execute_reply": "2025-04-12T08:57:24.154646Z"
        },
        "id": "_Ydo-LY8OJfG"
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算残差收益率\n",
        "def calculate_residual_return(data, factor_pool):\n",
        "    if not factor_pool:\n",
        "        # 展平 data['return'] 为一维数组\n",
        "        residual = data['return'].values.flatten()\n",
        "        print(f\"初始残差收益率形状: {data['return'].shape}, 展平后: {residual.shape}\")\n",
        "        return pd.Series(residual)\n",
        "    try:\n",
        "        X = np.column_stack([eval(formula, {'np': np, 'bn': bn}, {'data': data}) for formula in factor_pool])\n",
        "        y = data['return'].values.flatten()\n",
        "        mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))\n",
        "        if mask.sum() < 2:\n",
        "            print(\"残差计算数据点不足，返回原始收益率\")\n",
        "            return pd.Series(y)\n",
        "        lr = LinearRegression()\n",
        "        lr.fit(X[mask], y[mask])\n",
        "        residuals = y - lr.predict(X)\n",
        "        print(f\"残差计算后形状: {residuals.shape}\")\n",
        "        return pd.Series(residuals)\n",
        "    except Exception as e:\n",
        "        print(f\"残差计算错误: {e}\")\n",
        "        return pd.Series(data['return'].values.flatten())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "es5LrLciOJfG"
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": [
        "# 修改后的 rolling_factor_extraction 函数（更新了 function_list）\n",
        "def rolling_factor_extraction(start_date, end_date, interval_years=2):\n",
        "    stock_list = get_hs300_top50(start_date, end_date)\n",
        "    if not stock_list:\n",
        "        print(\"无法获取股票列表，退出\")\n",
        "        return []\n",
        "\n",
        "    current_date = pd.to_datetime(start_date)\n",
        "    end_date = pd.to_datetime(end_date)\n",
        "    factor_pool = []\n",
        "    # 更新因子公式，增加复杂性和多样性\n",
        "    function_list = [\n",
        "        \"data['open'] / (data['close'] + 1e-10)\",  # 价格比率\n",
        "        \"(data['high'] - data['low']) / (data['close'] + 1e-10)\",  # 波动性\n",
        "        \"bn.move_mean(data['volume'], window=5) / (bn.move_mean(data['volume'], window=20) + 1e-10)\",  # 成交量均值比率\n",
        "        \"np.log(data['close'] + 1) - np.log(bn.move_mean(data['close'], window=5) + 1)\",  # 价格对数差\n",
        "        \"bn.nanrankdata(data['close'].diff(1), axis=0) / (data['close'] + 1e-10)\",  # 价格变化排名\n",
        "        \"(data['close'] - bn.move_mean(data['close'], window=10)) / bn.move_std(data['close'], window=10)\"  # 标准化价格偏差\n",
        "    ]\n",
        "\n",
        "    # 设置最早数据日期\n",
        "    earliest_date = pd.to_datetime('20150101')\n",
        "\n",
        "    while current_date < end_date:\n",
        "        sample_start = (current_date - pd.DateOffset(years=2))\n",
        "        if sample_start < earliest_date:\n",
        "            sample_start = earliest_date\n",
        "        sample_start = sample_start.strftime('%Y%m%d')\n",
        "        sample_end = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        print(f\"正在处理窗口: {sample_start} 至 {sample_end}\")\n",
        "        data = get_data(sample_start, sample_end, stock_list)\n",
        "\n",
        "        if data.empty:\n",
        "            print(f\"无数据: {sample_start} 至 {sample_end}\")\n",
        "            current_date += pd.DateOffset(years=interval_years)\n",
        "            continue\n",
        "\n",
        "        population_size = 200\n",
        "        generations = 2\n",
        "        population = initialize_population(population_size, function_list)\n",
        "\n",
        "        try:\n",
        "            residual_return = calculate_residual_return(data, factor_pool)\n",
        "            # 确保 residual_return 是一维数组\n",
        "            if isinstance(residual_return, pd.Series):\n",
        "                residual_return_flat = residual_return.values\n",
        "            else:\n",
        "                residual_return_flat = residual_return.flatten()\n",
        "            print(f\"残差收益率统计: min={np.nanmin(residual_return_flat):.4f}, max={np.nanmax(residual_return_flat):.4f}, std={np.nanstd(residual_return_flat):.4f}\")\n",
        "\n",
        "            print(\"开始进化种群...\")\n",
        "            final_population = evolve_population(population, data, generations)\n",
        "            print(f\"最终种群大小: {len(final_population)}\")\n",
        "\n",
        "            for formula in final_population:\n",
        "                try:\n",
        "                    factor_values = eval(formula, {'np': np, 'bn': bn}, {'data': data})\n",
        "                    # 展平二维数组，确保顺序一致\n",
        "                    if isinstance(factor_values, pd.DataFrame):\n",
        "                        factor_values_flat = factor_values.values.flatten()\n",
        "                    else:\n",
        "                        factor_values_flat = factor_values.flatten()\n",
        "                    mask = ~(np.isnan(factor_values_flat) | np.isnan(residual_return_flat))\n",
        "                    if mask.sum() < 2:\n",
        "                        print(f\"因子 {formula} 有效数据点少于 2，跳过\")\n",
        "                        continue\n",
        "\n",
        "                    corr, _ = spearmanr(factor_values_flat[mask], residual_return_flat[mask])\n",
        "                    # print(f\"因子 {formula} 与残差的相关性: {corr:.4f}\")\n",
        "\n",
        "                    if abs(corr) < 0.7 and not np.isnan(corr):\n",
        "                        factor_pool.append(formula)\n",
        "                        # print(f\"添加因子: {formula}, 相关性: {corr:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"因子 {formula} 处理失败: {e}\")\n",
        "                    continue\n",
        "        except Exception as e:\n",
        "            print(f\"处理错误: {e}\")\n",
        "            continue\n",
        "\n",
        "        current_date += pd.DateOffset(years=interval_years)\n",
        "        factor_pool = factor_pool[-100:]\n",
        "\n",
        "    return factor_pool,data"
      ],
      "metadata": {
        "trusted": true,
        "id": "AqeN7ij1OJfG"
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "# 回测函数\n",
        "def backtest_synthetic_factor(start_date, end_date, stock_list, factor_file=\"synthetic_factor.csv\"):\n",
        "    \"\"\"\n",
        "    利用合成因子进行回测，评估其表现。\n",
        "\n",
        "    参数：\n",
        "    start_date (str): 回测开始日期，格式 'YYYYMMDD'\n",
        "    end_date (str): 回测结束日期，格式 'YYYYMMDD'\n",
        "    stock_list (list): 股票池\n",
        "    factor_file (str): 合成因子文件路径\n",
        "\n",
        "    返回：\n",
        "    None\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # 1. 加载合成因子\n",
        "    try:\n",
        "        factor_df = pd.read_csv(factor_file)\n",
        "        factor_df['date'] = pd.to_datetime(factor_df['date'])\n",
        "        factor_df.set_index('date', inplace=True)\n",
        "        print(f\"加载合成因子数据：{factor_df.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"加载合成因子文件失败：{e}\")\n",
        "        return\n",
        "\n",
        "    # 2. 获取回测期间的股票数据\n",
        "    df_list = []\n",
        "    for stock in stock_list:\n",
        "        try:\n",
        "            temp_df = pro.daily(\n",
        "                ts_code=stock,\n",
        "                start_date=start_date,\n",
        "                end_date=end_date,\n",
        "                fields='ts_code,trade_date,close,pct_chg'\n",
        "            )\n",
        "            if not temp_df.empty:\n",
        "                df_list.append(temp_df)\n",
        "            else:\n",
        "                print(f\"股票 {stock} 在 {start_date} 至 {end_date} 无数据\")\n",
        "        except Exception as e:\n",
        "            print(f\"获取股票 {stock} 数据失败：{e}\")\n",
        "\n",
        "    if not df_list:\n",
        "        print(f\"时间范围 {start_date} 至 {end_date} 无任何股票数据\")\n",
        "        return\n",
        "\n",
        "    # 合并数据\n",
        "    df = pd.concat(df_list)\n",
        "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
        "    df['pct_chg'] = df['pct_chg'] / 100  # 转换为小数\n",
        "    df_pivot = df.pivot(index='trade_date', columns='ts_code', values=['close', 'pct_chg'])\n",
        "    print(f\"回测数据形状：{df_pivot.shape}\")\n",
        "\n",
        "    # 3. 准备因子和收益数据\n",
        "    # 假设因子值是展平的，需要重新整理为 (日期, 股票) 的形状\n",
        "    dates = df_pivot.index\n",
        "    stocks = df_pivot['close'].columns\n",
        "    n_dates = len(dates)\n",
        "    n_stocks = len(stocks)\n",
        "    expected_length = n_dates * n_stocks\n",
        "\n",
        "    # 检查因子数据长度\n",
        "    if len(factor_df) != expected_length:\n",
        "        print(f\"因子数据长度 {len(factor_df)} 与预期长度 {expected_length} 不一致，调整中...\")\n",
        "        factor_df = factor_df.iloc[:expected_length]\n",
        "\n",
        "    # 重塑因子值为 (日期, 股票) 的矩阵\n",
        "    factor_values = factor_df['synthetic_factor'].values.reshape(n_dates, n_stocks)\n",
        "    factor_df_reshaped = pd.DataFrame(factor_values, index=dates, columns=stocks)\n",
        "\n",
        "    # 获取每日收益率\n",
        "    returns = df_pivot['pct_chg']\n",
        "\n",
        "    # 4. 构建投资组合\n",
        "    portfolio_returns = []\n",
        "    for date in returns.index:\n",
        "        # 获取当日的因子值和收益率\n",
        "        if date not in factor_df_reshaped.index:\n",
        "            portfolio_returns.append(0.0)\n",
        "            continue\n",
        "        factor_values_day = factor_df_reshaped.loc[date]\n",
        "        returns_day = returns.loc[date]\n",
        "\n",
        "        # 过滤掉因子值或收益率为 NaN 的股票\n",
        "        valid_mask = ~factor_values_day.isna() & ~returns_day.isna()\n",
        "        factor_values_day = factor_values_day[valid_mask]\n",
        "        returns_day = returns_day[valid_mask]\n",
        "\n",
        "        if len(factor_values_day) < 2:\n",
        "            portfolio_returns.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # 根据因子值排序\n",
        "        factor_rank = factor_values_day.rank()\n",
        "        total_stocks = len(factor_rank)\n",
        "        top_threshold = int(total_stocks * 0.8)  # 前 20%\n",
        "        bottom_threshold = int(total_stocks * 0.2)  # 后 20%\n",
        "\n",
        "        # 多头组合：因子值排名前 20% 的股票\n",
        "        long_stocks = factor_rank[factor_rank > top_threshold].index\n",
        "        # 空头组合：因子值排名后 20% 的股票\n",
        "        short_stocks = factor_rank[factor_rank <= bottom_threshold].index\n",
        "\n",
        "        # 计算多头和空头组合的收益率（等权重）\n",
        "        long_return = returns_day[long_stocks].mean() if len(long_stocks) > 0 else 0.0\n",
        "        short_return = returns_day[short_stocks].mean() if len(short_stocks) > 0 else 0.0\n",
        "\n",
        "        # 多空组合收益率\n",
        "        portfolio_return = long_return - short_return\n",
        "        portfolio_returns.append(portfolio_return if not np.isnan(portfolio_return) else 0.0)\n",
        "\n",
        "    # 5. 计算回测指标\n",
        "    portfolio_returns = pd.Series(portfolio_returns, index=returns.index)\n",
        "\n",
        "    # 累计收益率\n",
        "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
        "\n",
        "    # 年化收益率\n",
        "    n_days = len(portfolio_returns)\n",
        "    n_years = n_days / 252  # 假设一年252个交易日\n",
        "    annualized_return = (cumulative_returns.iloc[-1]) ** (1 / n_years) - 1\n",
        "\n",
        "    # 年化波动率\n",
        "    annualized_volatility = portfolio_returns.std() * np.sqrt(252)\n",
        "\n",
        "    # 最大回撤\n",
        "    cumulative_max = cumulative_returns.cummax()\n",
        "    drawdowns = (cumulative_returns - cumulative_max) / cumulative_max\n",
        "    max_drawdown = drawdowns.min()\n",
        "\n",
        "    # 夏普比率（假设无风险利率为0）\n",
        "    sharpe_ratio = (annualized_return / annualized_volatility) if annualized_volatility != 0 else 0.0\n",
        "\n",
        "    # 6. 输出回测结果\n",
        "    print(\"\\n回测结果：\")\n",
        "    print(f\"累计收益率：{cumulative_returns.iloc[-1] - 1:.4f}\")\n",
        "    print(f\"年化收益率：{annualized_return:.4f}\")\n",
        "    print(f\"年化波动率：{annualized_volatility:.4f}\")\n",
        "    print(f\"最大回撤：{max_drawdown:.4f}\")\n",
        "    print(f\"夏普比率：{sharpe_ratio:.4f}\")\n",
        "\n",
        "    # 7. 可视化累计收益率\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cumulative_returns, label='累计收益率')\n",
        "    plt.title('合成因子多空组合累计收益率')\n",
        "    plt.xlabel('日期')\n",
        "    plt.ylabel('累计收益率')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MtGS981mZLFZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 主函数\n",
        "def main():\n",
        "    start_date = '20180101'\n",
        "    end_date = '20240101'\n",
        "    print(f\"因子挖掘范围: {start_date} 至 {end_date}\")\n",
        "\n",
        "    # 因子挖掘\n",
        "    rolling_factors, data = rolling_factor_extraction(start_date, end_date)\n",
        "    print(\"挖掘的因子公式:\")\n",
        "    if not rolling_factors:\n",
        "        print(\"因子池为空，可能是因子公式无效或数据问题，请检查日志\")\n",
        "        return\n",
        "\n",
        "    for factor in rolling_factors:\n",
        "        print(f'{factor}\\n')\n",
        "\n",
        "    # 因子合成\n",
        "    print(\"开始因子合成...\")\n",
        "    # 准备目标变量（下一期收益率）\n",
        "    target = data['return'].shift(-1).values.flatten()\n",
        "    # 计算所有因子的值，传递 target 的形状\n",
        "    factors = calculate_all_factors(data, rolling_factors, target_shape=target.shape)\n",
        "\n",
        "    # 确保 factors 和 target 的样本数一致\n",
        "    if factors.shape[0] != len(target):\n",
        "        print(f\"factors 形状 {factors.shape[0]} 与 target 长度 {len(target)} 不一致，调整中...\")\n",
        "        min_length = min(factors.shape[0], len(target))\n",
        "        factors = factors[:min_length]\n",
        "        target = target[:min_length]\n",
        "\n",
        "    # 使用随机森林进行因子合成\n",
        "    final_factor, rf_model = synthesize_with_random_forest(factors, target)\n",
        "\n",
        "    # 保存结果\n",
        "    save_results(final_factor, data)\n",
        "\n",
        "    # 输出特征重要性\n",
        "    if rf_model is not None:\n",
        "        feature_importances = pd.Series(rf_model.feature_importances_, index=[f\"Factor_{i+1}\" for i in range(len(rolling_factors))])\n",
        "        print(\"\\n特征重要性（前10个因子）：\")\n",
        "        print(feature_importances.sort_values(ascending=False).head(10))\n",
        "\n",
        "    # 回测\n",
        "    print(\"\\n开始回测...\")\n",
        "    stock_list = get_hs300_top50(start_date, end_date)  # 获取股票池\n",
        "    backtest_synthetic_factor(start_date, end_date, stock_list)"
      ],
      "metadata": {
        "id": "ONqpJTllWA84"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 主函数\n",
        "# def main():\n",
        "#     start_date = '20180101'\n",
        "#     end_date = '20240101'\n",
        "#     print(f\"因子挖掘范围: {start_date} 至 {end_date}\")\n",
        "\n",
        "#     # 因子挖掘\n",
        "#     rolling_factors, data = rolling_factor_extraction(start_date, end_date)\n",
        "#     print(\"挖掘的因子公式:\")\n",
        "#     if not rolling_factors:\n",
        "#         print(\"因子池为空，可能是因子公式无效或数据问题，请检查日志\")\n",
        "#         return\n",
        "\n",
        "#     for factor in rolling_factors:\n",
        "#         print(f'{factor}\\n')\n",
        "\n",
        "#     # 因子合成\n",
        "#     print(\"开始因子合成...\")\n",
        "#     # 准备目标变量（下一期收益率）\n",
        "#     target = data['return'].shift(-1).values.flatten()\n",
        "#     # 计算所有因子的值，传递 target 的形状\n",
        "#     factors = calculate_all_factors(data, rolling_factors, target_shape=target.shape)\n",
        "\n",
        "#     # 确保 factors 和 target 的样本数一致\n",
        "#     if factors.shape[0] != len(target):\n",
        "#         print(f\"factors 形状 {factors.shape[0]} 与 target 长度 {len(target)} 不一致，调整中...\")\n",
        "#         min_length = min(factors.shape[0], len(target))\n",
        "#         factors = factors[:min_length]\n",
        "#         target = target[:min_length]\n",
        "\n",
        "#     # 使用随机森林进行因子合成\n",
        "#     final_factor, rf_model = synthesize_with_random_forest(factors, target)\n",
        "\n",
        "#     # 保存结果\n",
        "#     save_results(final_factor, data)\n",
        "\n",
        "#     # 输出特征重要性\n",
        "#     if rf_model is not None:\n",
        "#         feature_importances = pd.Series(rf_model.feature_importances_, index=[f\"Factor_{i+1}\" for i in range(len(rolling_factors))])\n",
        "#         print(\"\\n特征重要性（前10个因子）：\")\n",
        "#         print(feature_importances.sort_values(ascending=False).head(10))\n"
      ],
      "metadata": {
        "id": "YGyrAJsARBiy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2oE6Wk5PF1G",
        "outputId": "fcfb9ecf-30e5-4c63-c609-cd97048c7324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "因子挖掘范围: 20180101 至 20240101\n",
            "成功获取沪深300前50只股票: ['600519.SH', '601398.SH', '601288.SH', '601857.SH', '601988.SH', '601628.SH']...（共 100 只）\n",
            "正在处理窗口: 20160101 至 20180101\n",
            "股票 601728.SH 在 20160101 至 20180101 无数据\n",
            "股票 601658.SH 在 20160101 至 20180101 无数据\n",
            "股票 601138.SH 在 20160101 至 20180101 无数据\n",
            "股票 601816.SH 在 20160101 至 20180101 无数据\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rvK2l8KZQGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}